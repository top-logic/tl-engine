class.com.top_logic.kafka.script.I18NConstants.ERROR_KAFKA_SERVICE_NOT_STARTED = The Kafka service is not started.
com.top_logic.kafka.interceptor.TopicSensorAndViewerInterceptor = Topic sensor and viewer interceptor
com.top_logic.kafka.interceptor.TopicSensorAndViewerInterceptor.tooltip = Combine message and sensor view as an interceptor.
com.top_logic.kafka.interceptor.TopicViewerInterceptor = Topic viewer interceptor
com.top_logic.kafka.interceptor.TopicViewerInterceptor.Config.queue-size = Queue size
com.top_logic.kafka.interceptor.TopicViewerInterceptor.Config.queue-size.tooltip = Size of the internal queue of <i>kafka messages</i>.
com.top_logic.kafka.interceptor.TopicViewerInterceptor.tooltip = Convert consumed records from kafka into <i>sensor</i> entries.
com.top_logic.kafka.layout.kafka.KafkaTopicListModelBuilder = Kafka topic list model builder
com.top_logic.kafka.layout.kafka.KafkaTopicListModelBuilder.tooltip = Build up the list of topics relevant to the user.
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent = Progress tree table component
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent.Config.default-active = Default active
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent.Config.default-active.tooltip = Whether automatic update is enabled by default.
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent.Config.update-interval = Update interval
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent.Config.update-interval.tooltip = The time between two UI refreshes in milliseconds.
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent.Config.updater = Updater
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent.Config.updater.tooltip = Helper class for finding rows to be updated.
com.top_logic.kafka.layout.kafka.ProgressTreeTableComponent.tooltip = Tree based table which can change it's content without user interaction.
com.top_logic.kafka.layout.kafka.TopicMessagesTableModelBuilder = Topic messages table model builder
com.top_logic.kafka.layout.kafka.TopicMessagesTableModelBuilder.Config.topic = Topic
com.top_logic.kafka.layout.kafka.TopicMessagesTableModelBuilder.Config.topic.tooltip = The name of the topic to display the contents for
com.top_logic.kafka.layout.kafka.TopicMessagesTableModelBuilder.tooltip = A <i>list model builder</i> which displays the contents of the configured topic.
com.top_logic.kafka.layout.kafka.TopicMessagesTableUpdater = Topic messages table updater
com.top_logic.kafka.layout.kafka.TopicMessagesTableUpdater.Config.topic = Topic
com.top_logic.kafka.layout.kafka.TopicMessagesTableUpdater.Config.topic.tooltip = The name of the topic to display the contents for
com.top_logic.kafka.layout.kafka.TopicMessagesTableUpdater.tooltip = <i>Table component value updater</i> implementation which resolves new messages for the configured topic only.
com.top_logic.kafka.layout.sensors.ProgressTableComponent = Progress table component
com.top_logic.kafka.layout.sensors.ProgressTableComponent.Config.default-active = Default active
com.top_logic.kafka.layout.sensors.ProgressTableComponent.Config.default-active.tooltip = Whether automatic update is enabled by default.
com.top_logic.kafka.layout.sensors.ProgressTableComponent.Config.update-interval = Update interval
com.top_logic.kafka.layout.sensors.ProgressTableComponent.Config.update-interval.tooltip = The time between two UI refreshes in milliseconds.
com.top_logic.kafka.layout.sensors.ProgressTableComponent.Config.updater = Updater
com.top_logic.kafka.layout.sensors.ProgressTableComponent.Config.updater.tooltip = Helper class for finding rows to be updated.
com.top_logic.kafka.layout.sensors.ProgressTableComponent.tooltip = Table component automatically updating its values via the <i>Updater</i>.
com.top_logic.kafka.layout.sensors.SensorListModelBuilder = Sensor list model builder
com.top_logic.kafka.layout.sensors.SensorListModelBuilder.Config.exclude-topics = Exclude topics
com.top_logic.kafka.layout.sensors.SensorListModelBuilder.Config.exclude-topics.tooltip = Optional list of topics to be excluded. <p> All topics included in this set are not contained in the model. </p>
com.top_logic.kafka.layout.sensors.SensorListModelBuilder.Config.include-topics = Include topics
com.top_logic.kafka.layout.sensors.SensorListModelBuilder.Config.include-topics.tooltip = Optional list of topics to be included. <p> If not empty, only those topics that are contained in the set (but not in <i>Exclude topics</i>) are contained in the model. </p>
com.top_logic.kafka.layout.sensors.SensorListModelBuilder.tooltip = Build up the list of sensors relevant to the user.
com.top_logic.kafka.log.KafkaNoContentsLogWriter = No message contents
com.top_logic.kafka.log.KafkaNoContentsLogWriter.tooltip = <i>Kafka log writer</i> that does not log message contents. <p> Message contents is not written to the Kafka log. </p>
com.top_logic.kafka.log.KafkaStringLogWriter = Complete string message contents
com.top_logic.kafka.log.KafkaStringLogWriter.tooltip = <i>Kafka log writer</i> for <i>string</i> messages. <p> Note: This implementation can only be used, if a string messages are sent. For a consumer, this means that a string deserializer must be in use. </p>
com.top_logic.kafka.monitor.KafkaReceiverApplicationMonitor = Kafka receiver application monitor
com.top_logic.kafka.monitor.KafkaReceiverApplicationMonitor.Config.max-processing-time = Maximum processing time
com.top_logic.kafka.monitor.KafkaReceiverApplicationMonitor.Config.max-processing-time.tooltip = How long a receive operation can run, before it is considered to be "too long".
com.top_logic.kafka.monitor.KafkaReceiverApplicationMonitor.tooltip = The <i>application health monitor</i> for the Kafka binding for receiving. <p> It reports <i>error</i>, whenever receiving is not possible, irrespective of the reason. Therefore, it will for example report <i>error</i> during the application startup, until the relevant services have been started. Only the user can decide, whether it is currently okay that this service is not operational. If this class reported "okay" in such cases, it would mislead the problem analysis if it was not correct that this service is for example not started or shut down. </p>
com.top_logic.kafka.monitor.KafkaSenderApplicationMonitor = Kafka sender application monitor
com.top_logic.kafka.monitor.KafkaSenderApplicationMonitor.tooltip = The <i>application health monitor</i> for the Kafka binding for sending. <p> It reports <i>error</i>, whenever sending is not possible, irrespective of the reason. Therefore, it will for example report <i>error</i> during the application startup, until the relevant services have been started. Only the user can decide, whether it is currently okay that this service is not operational. If this class reported "okay" in such cases, it would mislead the problem analysis if it was not correct that this service is for example not started or shut down. </p>
com.top_logic.kafka.script.ConsumerProcessorByExpression = TL-Script message processor
com.top_logic.kafka.script.ConsumerProcessorByExpression.Config.processor = Processor
com.top_logic.kafka.script.ConsumerProcessorByExpression.Config.processor.tooltip = The TL-Script that is called for each received message. <p> The script implicitly declares the the following parameters: <ol> <li>message: String.</li> <li>key: String</li> <li>headers: A list of key-value-pairs. Both are Strings. There can be multiple headers with the same key. Kafka header values are actually binary data. As they are usually Strings though, they are interpreted as UTF-8 Strings here for convenience.</li> <li>topic: String</li> </ol> </p> <p> The parameters are declared implicitly and can be directly used with <code>$message</code> without declaring a function. </p> <p> The message is automatically acknowledged, if the script does not throw an error. The result of the script is ignored. </p>
com.top_logic.kafka.script.ConsumerProcessorByExpression.Config.transaction = Transaction
com.top_logic.kafka.script.ConsumerProcessorByExpression.Config.transaction.tooltip = Whether to execute the <i>Processor</i> in a transaction context. <p> To create or modify persistent objects in the <i>Processor</i>, a transaction context is necessary. </p>
com.top_logic.kafka.script.ConsumerProcessorByExpression.tooltip = A <i>consumer processor</i> that can be configured In-App to process text messages. <p> Messages are consumed in-order, as long as there is only one partition for the Kafka topic and all messages come from the same sender. </p> <p> Every message is processed at least once. Messages may be received in groups. When processing at least one message in a group fails for at least one <i>consumer processor</i>, the entire group will be processed again by every registered <i>consumer processor</i>. </p>
com.top_logic.kafka.script.KafkaSend$Builder = Builder
com.top_logic.kafka.script.KafkaSend$Builder.tooltip = <i>Method builder</i> creating <i>kafka send</i>.
com.top_logic.kafka.scripting.WaitForKafkaActionOp = Wait for kafka action
com.top_logic.kafka.scripting.WaitForKafkaActionOp.tooltip = <i>Application action</i> for <i>wait for kafka action</i>.
com.top_logic.kafka.serialization.BinaryDataDeserializer = Binary data deserializer
com.top_logic.kafka.serialization.BinaryDataDeserializer.Config.content-type = Content type
com.top_logic.kafka.serialization.BinaryDataDeserializer.Config.content-type.tooltip = The content type to assume for the received message data.
com.top_logic.kafka.serialization.BinaryDataDeserializer.tooltip = A <i>deserializer</i> interprets contents as binary data that must be further processed by the message processor.
com.top_logic.kafka.serialization.GenericSerializer = Generic serializer
com.top_logic.kafka.serialization.GenericSerializer.Config.encoding = Encoding
com.top_logic.kafka.serialization.GenericSerializer.Config.encoding.tooltip = The encoding for character contents. <p> The value is irrelevant, if binary data is transmitted. </p>
com.top_logic.kafka.serialization.GenericSerializer.tooltip = A generic <i>serializer</i> that is compatible with <i>binary data</i>, <i>list</i>, <i>map</i>, <i>HTML fragment</i> and <i>string</i>. <p> Contents of <i>binary data</i> is transmitted as is. <i>List</i> and <i>map</i> values are transmitted JSON-encoded. <i>HTML fragment</i> are transmitted as XML with the given encoding. All other values are converted to <i>string</i> and transmitted with the given encoding. </p>
com.top_logic.kafka.serialization.JSONDeserializer = JSON deserializer
com.top_logic.kafka.serialization.JSONDeserializer.Config.encoding = Encoding
com.top_logic.kafka.serialization.JSONDeserializer.Config.encoding.tooltip = The encoding of message contents.
com.top_logic.kafka.serialization.JSONDeserializer.tooltip = A <i>deserializer</i> interprets contents as JSON encoded objects.
com.top_logic.kafka.serialization.JSONSerializer = JSON serializer
com.top_logic.kafka.serialization.JSONSerializer.Config.encoding = Encoding
com.top_logic.kafka.serialization.JSONSerializer.Config.encoding.tooltip = The encoding for character contents.
com.top_logic.kafka.serialization.JSONSerializer.tooltip = A <i>serializer</i> encodes values as JSON objects. <p> In contrast to the <i>generic serializer</i>, also primitive values such as numbers and strings are JSON encoded. </p>
com.top_logic.kafka.serialization.StringDeserializer = String deserializer
com.top_logic.kafka.serialization.StringDeserializer.Config.encoding = Encoding
com.top_logic.kafka.serialization.StringDeserializer.Config.encoding.tooltip = The encoding of message contents.
com.top_logic.kafka.serialization.StringDeserializer.tooltip = A <i>deserializer</i> interprets contents as text in a given encoding.
com.top_logic.kafka.serialization.StringSerializer = String serializer
com.top_logic.kafka.serialization.StringSerializer.Config.encoding = Encoding
com.top_logic.kafka.serialization.StringSerializer.Config.encoding.tooltip = The encoding for character contents. <p> The value is irrelevant, if binary data is transmitted. </p>
com.top_logic.kafka.serialization.StringSerializer.tooltip = A <i>serializer</i> that creates messages by interpreting values as <i>strings</i> and encodes them with a given character set.
com.top_logic.kafka.services.common.CommonClientConfig.all-properties = All properties
com.top_logic.kafka.services.common.CommonClientConfig.all-properties.tooltip = The Kafka <i>properties</i> to be used for <i>kafka common client</i> instantiation. A new, mutable and resizable <i>map</i>.
com.top_logic.kafka.services.common.CommonClientConfig.auto.include.jmx.reporter = Auto include jmx reporter
com.top_logic.kafka.services.common.CommonClientConfig.bootstrap.servers = Bootstrap servers
com.top_logic.kafka.services.common.CommonClientConfig.client.dns.lookup = Client dns lookup
com.top_logic.kafka.services.common.CommonClientConfig.client.id = Client ID
com.top_logic.kafka.services.common.CommonClientConfig.client.id.tooltip = NOTE: not all characters are admissible, e.g. the character ':' must be avoided.
com.top_logic.kafka.services.common.CommonClientConfig.connections.max.idle.ms = Connections maximum idle ms
com.top_logic.kafka.services.common.CommonClientConfig.log-writer = Log writer
com.top_logic.kafka.services.common.CommonClientConfig.log-writer.tooltip = The <i>kafka log writer</i> to use for logging the messages.
com.top_logic.kafka.services.common.CommonClientConfig.metadata.max.age.ms = Metadata maximum age ms
com.top_logic.kafka.services.common.CommonClientConfig.metric.reporters = Metric reporters
com.top_logic.kafka.services.common.CommonClientConfig.metrics.num.samples = Metrics number samples
com.top_logic.kafka.services.common.CommonClientConfig.metrics.recording.level = Metrics recording level
com.top_logic.kafka.services.common.CommonClientConfig.metrics.sample.window.ms = Metrics sample window ms
com.top_logic.kafka.services.common.CommonClientConfig.receive.buffer.bytes = Receive buffer bytes
com.top_logic.kafka.services.common.CommonClientConfig.reconnect.backoff.max.ms = Reconnect backoff maximum ms
com.top_logic.kafka.services.common.CommonClientConfig.reconnect.backoff.ms = Reconnect backoff ms
com.top_logic.kafka.services.common.CommonClientConfig.request.timeout.ms = Request timeout ms
com.top_logic.kafka.services.common.CommonClientConfig.retry.backoff.ms = Retry backoff ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.client.callback.handler.class = Sasl client callback handler class
com.top_logic.kafka.services.common.CommonClientConfig.sasl.jaas.config = Sasl jaas configuration
com.top_logic.kafka.services.common.CommonClientConfig.sasl.kerberos.kinit.cmd = Sasl kerberos kinit cmd
com.top_logic.kafka.services.common.CommonClientConfig.sasl.kerberos.min.time.before.relogin = Sasl kerberos minimum time before relogin
com.top_logic.kafka.services.common.CommonClientConfig.sasl.kerberos.service.name = Sasl kerberos service name
com.top_logic.kafka.services.common.CommonClientConfig.sasl.kerberos.ticket.renew.jitter = Sasl kerberos ticket renew jitter
com.top_logic.kafka.services.common.CommonClientConfig.sasl.kerberos.ticket.renew.window.factor = Sasl kerberos ticket renew window factor
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.callback.handler.class = Sasl login callback handler class
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.class = Sasl login class
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.connect.timeout.ms = Sasl login connect timeout ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.read.timeout.ms = Sasl login read timeout ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.refresh.buffer.seconds = Sasl login refresh buffer seconds
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.refresh.min.period.seconds = Sasl login refresh minimum period seconds
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.refresh.window.factor = Sasl login refresh window factor
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.refresh.window.jitter = Sasl login refresh window jitter
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.retry.backoff.max.ms = Sasl login retry backoff maximum ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.login.retry.backoff.ms = Sasl login retry backoff ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.mechanism = Sasl mechanism
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.clock.skew.seconds = Sasl oauthbearer clock skew seconds
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.expected.audience = Sasl oauthbearer expected audience
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.expected.issuer = Sasl oauthbearer expected issuer
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.jwks.endpoint.refresh.ms = Sasl oauthbearer jwks endpoint refresh ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = Sasl oauthbearer jwks endpoint retry backoff maximum ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = Sasl oauthbearer jwks endpoint retry backoff ms
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.jwks.endpoint.url = Sasl oauthbearer jwks endpoint URL
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.scope.claim.name = Sasl oauthbearer scope claim name
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.sub.claim.name = Sasl oauthbearer sub claim name
com.top_logic.kafka.services.common.CommonClientConfig.sasl.oauthbearer.token.endpoint.url = Sasl oauthbearer token endpoint URL
com.top_logic.kafka.services.common.CommonClientConfig.security.protocol = Security protocol
com.top_logic.kafka.services.common.CommonClientConfig.security.providers = Security providers
com.top_logic.kafka.services.common.CommonClientConfig.security.providers.tooltip = The Kafka configuration property: "security.providers"
com.top_logic.kafka.services.common.CommonClientConfig.send.buffer.bytes = Send buffer bytes
com.top_logic.kafka.services.common.CommonClientConfig.socket.connection.setup.timeout.max.ms = Socket connection setup timeout maximum ms
com.top_logic.kafka.services.common.CommonClientConfig.socket.connection.setup.timeout.ms = Socket connection setup timeout ms
com.top_logic.kafka.services.common.CommonClientConfig.ssl.cipher.suites = Ssl cipher suites
com.top_logic.kafka.services.common.CommonClientConfig.ssl.enabled.protocols = Ssl enabled protocols
com.top_logic.kafka.services.common.CommonClientConfig.ssl.endpoint.identification.algorithm = Ssl endpoint identification algorithm
com.top_logic.kafka.services.common.CommonClientConfig.ssl.engine.factory.class = Ssl engine factory class
com.top_logic.kafka.services.common.CommonClientConfig.ssl.key.password = Ssl key password
com.top_logic.kafka.services.common.CommonClientConfig.ssl.keymanager.algorithm = Ssl keymanager algorithm
com.top_logic.kafka.services.common.CommonClientConfig.ssl.keystore.certificate.chain = Ssl keystore certificate chain
com.top_logic.kafka.services.common.CommonClientConfig.ssl.keystore.key = Ssl keystore key
com.top_logic.kafka.services.common.CommonClientConfig.ssl.keystore.location = Ssl keystore location
com.top_logic.kafka.services.common.CommonClientConfig.ssl.keystore.password = Ssl keystore password
com.top_logic.kafka.services.common.CommonClientConfig.ssl.keystore.type = Ssl keystore type
com.top_logic.kafka.services.common.CommonClientConfig.ssl.protocol = Ssl protocol
com.top_logic.kafka.services.common.CommonClientConfig.ssl.provider = Ssl provider
com.top_logic.kafka.services.common.CommonClientConfig.ssl.secure.random.implementation = Ssl secure random implementation
com.top_logic.kafka.services.common.CommonClientConfig.ssl.trustmanager.algorithm = Ssl trustmanager algorithm
com.top_logic.kafka.services.common.CommonClientConfig.ssl.truststore.certificates = Ssl truststore certificates
com.top_logic.kafka.services.common.CommonClientConfig.ssl.truststore.location = Ssl truststore location
com.top_logic.kafka.services.common.CommonClientConfig.ssl.truststore.password = Ssl truststore password
com.top_logic.kafka.services.common.CommonClientConfig.ssl.truststore.type = Ssl truststore type
com.top_logic.kafka.services.common.CommonClientConfig.typed-properties = Typed properties
com.top_logic.kafka.services.common.CommonClientConfig.typed-properties.tooltip = The properties with an explicit <i>property descriptor</i> in the <i>configuration item</i>. <p> If a property is not set, the <i>map</i> will contain its default value. If the (default) value is null, the <i>map</i> will contain the key and value. </p>
com.top_logic.kafka.services.common.CommonClientConfig.untyped-properties = Additional properties
com.top_logic.kafka.services.common.CommonClientConfig.untyped-properties.tooltip = The map of Kafka configuration properties. <p> Properties which have dedicated TypedConfiguration properties must not be used here. </p>
com.top_logic.kafka.services.common.TopicChecker = Topic checker
com.top_logic.kafka.services.common.TopicChecker.Config.create-topics = Create topics
com.top_logic.kafka.services.common.TopicChecker.Config.create-topics.tooltip = Whether missing topics should be created.
com.top_logic.kafka.services.common.TopicChecker.Config.disabled = Disabled
com.top_logic.kafka.services.common.TopicChecker.Config.disabled.tooltip = Whether the check should be disabled. <p> Developers might want to disable the checks to start an application which uses Kafka without having to start Kafka. </p>
com.top_logic.kafka.services.common.TopicChecker.Config.wait-timeout = Wait timeout
com.top_logic.kafka.services.common.TopicChecker.Config.wait-timeout.tooltip = The timeout in milliseconds when waiting for the server response with the list of topics. <p> The value "0" means to not wait. Negative values are not allowed. To wait "forever" use <code>9223372036854775807</code>. </p>
com.top_logic.kafka.services.common.TopicChecker.tooltip = Checks whether topics exist on a Kafka server and creates missing topics.
com.top_logic.kafka.services.consumer.ConsumerDispatcher = Consumer dispatcher
com.top_logic.kafka.services.consumer.ConsumerDispatcher.tooltip = The consumer <i>thread</i> which will forward <i>consumer records</i> to all registered <i>consumer processors</i>.
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.allow.auto.create.topics = Allow auto create topics
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.allow.auto.create.topics.tooltip = The Kafka consumer property: "allow.auto.create.topics"
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.auto.commit.interval.ms = Auto commit interval ms
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.auto.offset.reset = Auto offset reset
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.check.crcs = Check crcs
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.client.rack = Client rack
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.client.rack.tooltip = The Kafka consumer property: "client.rack"
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.default.api.timeout.ms = Default api timeout ms
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.enable.auto.commit = Enable auto commit
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.error-pause-factor = Error pause factor
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.error-pause-factor.tooltip = When receiving messages keeps failing, the time between the retries increases by this factor every time. <p> When it fails for the first time, the first retry happens after <i>Error pause start</i> milliseconds. The second retry happens after <i>Error pause start</i> ms multiplied by this factor. The third retry happens after <code>start * factor * factor</code> ms and so on. But the time between retries never increases above <i>Error pause maximum</i>. It is capped there. When it has reached this value, it stays there, until the problem is resolved and receiving works again. The formula for the n'th retry is therefore: <code>min(error-pause-max, error-pause-start * (error-pause-factor ** (n-1)))</code> When it works again, but later starts failing again, the time between retries starts at <i>Error pause start</i> again. </p>
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.error-pause-max = Error pause maximum
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.error-pause-max.tooltip = The maximum pause in milliseconds when receiving messages keeps failing. <p> See <i>Error pause factor</i> for the formula for the error pauses in case of repeated failures. </p>
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.error-pause-start = Error pause start
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.error-pause-start.tooltip = The pause in milliseconds after an error happened. <p> This is necessary to prevent the <i>consumer dispatcher</i> from flooding the logs when a Kafka message cannot be processed. </p> <p> See <i>Error pause factor</i> for the formula for the error pauses in case of repeated failures. </p>
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.exclude.internal.topics = Exclude internal topics
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.fetch.max.bytes = Fetch maximum bytes
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.fetch.max.wait.ms = Fetch maximum wait ms
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.fetch.min.bytes = Fetch minimum bytes
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.group.id = Group ID
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.group.instance.id = Group instance ID
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.heartbeat.interval.ms = Heartbeat interval ms
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.interceptor.classes = Interceptor classes
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.isolation.level = Isolation level
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.key.deserializer = Key deserializer
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.key.deserializer.tooltip = When this option is not empty, <i>key deserializer</i> will be ignored.
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.key.deserializer.typed.config = Key deserializer
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.key.deserializer.typed.config.tooltip = Deserializer for message keys. <p> A deserializer converts binary data transmitted in a message to objects. </p>
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.max.partition.fetch.bytes = Maximum partition fetch bytes
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.max.poll.interval.ms = Maximum poll interval ms
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.max.poll.interval.ms.tooltip = When more than this much time passes between two requests, the client will be removed from the server.
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.max.poll.records = Maximum poll records
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.partition.assignment.strategy = Partition assignment strategy
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.polling-timeout = Polling timeout
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.polling-timeout.tooltip = The number of milliseconds to wait for the arrival of new messages
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.processors = Processors
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.processors.tooltip = A (possibly empty) <i>list</i> of configured <i>consumer processors</i>
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.session.timeout.ms = Session timeout ms
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.topics = Topics
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.topics.tooltip = A comma separated <i>set</i> of topic names to subscribe to.
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.value.deserializer = Value deserializer
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.value.deserializer.tooltip = When this option is not empty, <i>value deserializer</i> will be ignored.
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.value.deserializer.typed.config = Value deserializer
com.top_logic.kafka.services.consumer.ConsumerDispatcherConfiguration.value.deserializer.typed.config.tooltip = Deserializer for message contents. <p> A deserializer converts binary data transmitted in a message to objects. </p>
com.top_logic.kafka.services.consumer.KafkaClientProperty = Kafka client property
com.top_logic.kafka.services.consumer.KafkaClientProperty.tooltip = An <i>annotation</i> to flag <i>configuration item</i> properties as Kafka specific.
com.top_logic.kafka.services.consumer.KafkaConsumerService = Kafka consumer service
com.top_logic.kafka.services.consumer.KafkaConsumerService.Config.consumers = Consumers
com.top_logic.kafka.services.consumer.KafkaConsumerService.Config.consumers.tooltip = A (possibly empty) <i>list</i> of configured <i>consumer dispatchers</i>
com.top_logic.kafka.services.consumer.KafkaConsumerService.Config.join-timeout = Join timeout
com.top_logic.kafka.services.consumer.KafkaConsumerService.Config.join-timeout.tooltip = The amount of time (in milliseconds) to wait for a dispatcher thread to terminate
com.top_logic.kafka.services.consumer.KafkaConsumerService.tooltip = A service providing access to <i>kafka consumers</i>.
com.top_logic.kafka.services.producer.KafkaProducerService = Kafka producer service
com.top_logic.kafka.services.producer.KafkaProducerService.Config.producers = Producers
com.top_logic.kafka.services.producer.KafkaProducerService.Config.producers.tooltip = Configured <i>kafka producer's</i> by name
com.top_logic.kafka.services.producer.KafkaProducerService.tooltip = A <i>TopLogic service</i> providing kafka producer services.
com.top_logic.kafka.services.producer.TLKafkaProducer = Kafka producer
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.acks = Acks
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.acks.tooltip = The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. The following settings are allowed: <ul> <li><code>acks=0</code> If set to zero then the producer will not wait for any acknowledgment from the server at all. The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that the server has received the record in this case, and the <code>retries</code> configuration will not take effect (as the client won't generally know of any failures). The offset given back for each record will always be set to <code>-1</code>.</li> <li><code>acks=1</code> This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost.</li> <li><code>acks=all</code> This means the leader will wait for the full set of in-sync replicas to acknowledge the record. This guarantees that the record will not be lost as long as at least one in-sync replica remains alive. This is the strongest available guarantee. This is equivalent to the acks=-1 setting.</li> </ul> <p> Note that enabling idempotence requires this config value to be 'all'. If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled. </p>
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.batch.size = Batch size
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.batch.size.tooltip = The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server. This configuration controls the default batch size in bytes. <p> No attempt will be made to batch records larger than this size. </p> <p> Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent. </p> <p> A small batch size will make batching less common and may reduce throughput (a batch size of zero will disable batching entirely). A very large batch size may use memory a bit more wastefully as we will always allocate a buffer of the specified batch size in anticipation of additional records. </p> <p> Note: This setting gives the upper bound of the batch size to be sent. If we have fewer than this many bytes accumulated for this partition, we will 'linger' for the <code>linger.ms</code> time waiting for more records to show up. This <code>linger.ms</code> setting defaults to 0, which means we'll immediately send out a record even the accumulated batch size is under this <code>batch.size</code> setting. </p>
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.buffer.memory = Buffer memory
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.buffer.memory.tooltip = The total bytes of memory the producer can use to buffer records waiting to be sent to the server. If records are sent faster than they can be delivered to the server the producer will block for <i>Maximum block ms</i> after which it will throw an exception. <p> This setting should correspond roughly to the total memory the producer will use, but is not a hard bound since not all memory the producer uses is used for buffering. Some additional memory will be used for compression (if compression is enabled) as well as for maintaining in-flight requests. </p>
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.compression.type = Compression type
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.delivery.timeout.ms = Delivery timeout ms
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.enable.idempotence = Enable idempotence
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.interceptor.classes = Interceptor classes
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.key.serializer = Key serializer
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.key.serializer.tooltip = When this option is not empty, <i>Key serializer typed configuration</i> will be ignored.
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.key.serializer.typed.config = Key serializer typed configuration
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.key.serializer.typed.config.tooltip = This option is used only, when <i>Key serializer</i> is empty.
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.linger.ms = Linger ms
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.max.block.ms = Maximum block ms
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.max.in.flight.requests.per.connection = Maximum in flight requests per connection
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.max.request.size = Maximum request size
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.metadata.max.idle.ms = Metadata maximum idle ms
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.partitioner.adaptive.partitioning.enable = Partitioner adaptive partitioning enable
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.partitioner.availability.timeout.ms = Partitioner availability timeout ms
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.partitioner.class = Partitioner class
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.partitioner.ignore.keys = Partitioner ignore keys
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.retries = Retries
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.topic = Topic
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.topic.tooltip = The name of the KAFKA topic to write records to.
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.transaction.timeout.ms = Transaction timeout ms
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.transactional.id = Transactional ID
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.value.serializer = Value serializer
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.value.serializer.tooltip = When this option is not empty, <i>Value serializer typed configuration</i> will be ignored.
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.value.serializer.typed.config = Value serializer typed configuration
com.top_logic.kafka.services.producer.TLKafkaProducer.Config.value.serializer.typed.config.tooltip = This option is used only, when <i>Value serializer</i> is empty.
com.top_logic.kafka.services.producer.TLKafkaProducer.tooltip = Handler for sending data to a Kafka topic.
com.top_logic.kafka.services.sensors.DummySensorBuilder = Dummy sensor builder
com.top_logic.kafka.services.sensors.DummySensorBuilder.Config.duration = Duration
com.top_logic.kafka.services.sensors.DummySensorBuilder.Config.duration.tooltip = Delay between signal requests.
com.top_logic.kafka.services.sensors.DummySensorBuilder.Config.id = ID
com.top_logic.kafka.services.sensors.DummySensorBuilder.Config.id.tooltip = Unique ID of this dummy sensor.
com.top_logic.kafka.services.sensors.DummySensorBuilder.Config.name = Name
com.top_logic.kafka.services.sensors.DummySensorBuilder.Config.name.tooltip = Name of this dummy sensor.
com.top_logic.kafka.services.sensors.DummySensorBuilder.tooltip = Build dummy sensors which will generate random values.
com.top_logic.kafka.services.sensors.Sensor$SensorActivityState = Sensor activity state
com.top_logic.kafka.services.sensors.Sensor$SensorActivityState.tooltip = Possible states of a sensor.
com.top_logic.kafka.services.sensors.Sensor.SensorActivityState.ACTIVE = Active
com.top_logic.kafka.services.sensors.Sensor.SensorActivityState.ACTIVE.tooltip = Has been active in the last hour.
com.top_logic.kafka.services.sensors.Sensor.SensorActivityState.INACTIVE = Inactive
com.top_logic.kafka.services.sensors.Sensor.SensorActivityState.INACTIVE.tooltip = Has been inactive (or never been started).
com.top_logic.kafka.services.sensors.Sensor.SensorActivityState.RUNNING = Running
com.top_logic.kafka.services.sensors.Sensor.SensorActivityState.RUNNING.tooltip = Is currently active or has send a signal in the last minute.
com.top_logic.kafka.services.sensors.SensorService = Sensor service
com.top_logic.kafka.services.sensors.SensorService.Config.builders = Builders
com.top_logic.kafka.services.sensors.SensorService.Config.builders.tooltip = The builder to create the sensors of this service.
com.top_logic.kafka.services.sensors.SensorService.tooltip = Providing access to sensor instances.
